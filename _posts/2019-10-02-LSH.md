---
title: 局部敏感哈希
key: 20191002
tags: 机器学习
---

locality sensitive hashing

局部敏感哈希(Locality Sensitive Hashing，LSH)算法是我在前一段时间找工作时接触到的一种衡量文本相似度的算法。局部敏感哈希是近似最近邻搜索算法中最流行的一种，它有坚实的理论依据并且在高维数据空间中表现优异。它的主要作用就是从海量的数据中挖掘出相似的数据，可以具体应用到文本相似度检测、网页搜索等领域。
  　
局部敏感哈希的基本思想类似于一种空间域转换思想，LSH算法基于一个假设，如果两个文本在原有的数据空间是相似的，那么分别经过哈希函数转换以后的它们也具有很高的相似度；相反，如果它们本身是不相似的，那么经过转换后它们应仍不具有相似性。

某频道全量的两两相似度计算？一般没时间和资源
推荐的时候，不会用到所有的item，而是推荐topk个相似item经过排序的结果
解决方案是
1每个频道内的N个item进行聚类成M个类别（Kmeans、层次、二分等减少复杂度

2 LSH局部敏感哈希
思路：从海量数据库中寻找到与查询的数据相似的数据 例如文本搜索 图像检索等，
如果使用低维的小数据集，linear search足矣，但是对一个海量的高维数据集进行查找匹配的话，会非常耗时，可以加入索引的方法加速，如最近邻，kdtree等
LSH就是最近邻的一种
基本思想：如果两个文本在原有的数据空间是相似的，那么经过hash之后也具有高相似度
hash冲突难以避免，但是lsh依赖于冲突。希望越相似、离得越近的两个item发生冲突的概率越高，反之越低

LSH在线查找时间：
1.通过hash 计算bucket的时间
2.将查询数据与桶内的数据进行比较计算的时间 一般是对数时间或常数时间复杂度

lsh不能保证一定能查到和query最相邻的数据，但是可以减少需要匹配的数据点的个数，同时还能保证查找到最近邻的数据点的概率比较大。

LSH怎么做hash？
案例
minihash

1.对所有K个文档对应不同的词语进行标记，构成一个矩阵，并将词随机shuffle打乱得到新的矩阵，如图所示
然后文章进行重新标记，重复这种置换操作，打乱N次，每次都统计每一列（对应的是每个文档）第一个不为0位置的行号，如图中是1，2，1，2，记录成签名向量 得到N*K的矩阵 叫签名矩阵
（如果两篇文章相似，那么对应的两列的签名向量应该比较相似。）
2.对签名矩阵分割成b个band，对每个band（计算hash值，md5，sha1等）的K个文档段计算hash得到分散到若干个桶里，重复b个band

超参数 r b
一般控制这两个数 来控制两个文档被映射到同一个桶的概率

random projection
随机投影 映射到单位向量分到哈希桶里

Spark有BucketRandomProjectLSH


